{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unity ML-Agents Toolkit\n",
    "## Environment Basics\n",
    "This notebook contains a walkthrough of the basic functions of the Python API for the Unity ML-Agents toolkit. For instructions on building a Unity environment, see [here](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Getting-Started-with-Balance-Ball.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Set environment parameters\n",
    "\n",
    "Be sure to set `env_name` to the name of the Unity environment file you want to launch. Ensure that the environment build is in the `python/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"./Banana_Linux/Banana.x86_64\"\n",
    "train_mode = True  # Whether to run the environment in training or inference mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load dependencies\n",
    "\n",
    "The following loads the necessary dependencies and checks the Python version (at runtime). ML-Agents Toolkit (v0.3 onwards) requires Python 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version:\n",
      "3.6.8 (default, Jan 14 2019, 11:02:34) \n",
      "[GCC 8.0.1 20180414 (experimental) [trunk revision 259383]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "import random\n",
    "from collections import namedtuple, deque\n",
    "\n",
    "from unityagents import UnityEnvironment\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Python version:\")\n",
    "print(sys.version)\n",
    "\n",
    "# check Python version\n",
    "if (sys.version_info[0] < 3):\n",
    "    raise Exception(\"ERROR: ML-Agents Toolkit (v0.3 onwards) requires Python 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Start the environment\n",
    "`UnityEnvironment` launches and begins communication with the environment when instantiated.\n",
    "\n",
    "Environments contain _brains_ which are responsible for deciding the actions of their associated _agents_. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: BananaBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 37\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: BananaBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 37\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=env_name)\n",
    "\n",
    "# Examine environment parameters\n",
    "print(str(env))\n",
    "\n",
    "# Set the default brain to work with\n",
    "default_brain = env.brain_names[0]\n",
    "brain = env.brains[default_brain]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Examine the observation and state spaces\n",
    "We can reset the environment to be provided with an initial set of observations and states for all the agents within the environment. In ML-Agents, _states_ refer to a vector of variables corresponding to relevant aspects of the environment for an agent. Likewise, _observations_ refer to a set of relevant pixel-wise visuals for an agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent state looks like: \n",
      "[1.         0.         0.         0.         0.84408134 0.\n",
      " 0.         1.         0.         0.0748472  0.         1.\n",
      " 0.         0.         0.25755    1.         0.         0.\n",
      " 0.         0.74177343 0.         1.         0.         0.\n",
      " 0.25854847 0.         0.         1.         0.         0.09355672\n",
      " 0.         1.         0.         0.         0.31969345 0.\n",
      " 0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Reset the environment\n",
    "env_info = env.reset(train_mode=train_mode)[default_brain]\n",
    "\n",
    "# Examine the state space for the default brain\n",
    "print(\"Agent state looks like: \\n{}\".format(env_info.vector_observations[0]))\n",
    "\n",
    "# Examine the observation space for the default brain\n",
    "for observation in env_info.visual_observations:\n",
    "    print(\"Agent observations look like:\", observation.shape)\n",
    "    if observation.shape[3] == 3:\n",
    "        plt.imshow(observation[0,:,:,:])\n",
    "    else:\n",
    "        plt.imshow(observation[0,:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Take random actions in the environment\n",
    "Once we restart an environment, we can step the environment forward and provide actions to all of the agents within the environment. Here we simply choose random actions based on the `action_space_type` of the default brain. \n",
    "\n",
    "Once this cell is executed, 10 messages will be printed that detail how much reward will be accumulated for the next 10 episodes. The Unity environment will then pause, waiting for further signals telling it what to do next. Thus, not seeing any animation is expected when running this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reward this episode: 0.0\n"
     ]
    }
   ],
   "source": [
    "for episode in range(1):\n",
    "    env_info = env.reset(train_mode=train_mode)[default_brain]\n",
    "    done = False\n",
    "    episode_rewards = 0\n",
    "    while not done:\n",
    "        if brain.vector_action_space_type == 'continuous':\n",
    "            env_info = env.step(np.random.randn(len(env_info.agents), \n",
    "                                                brain.vector_action_space_size))[default_brain]\n",
    "        else:\n",
    "            env_info = env.step(np.random.randint(0, brain.vector_action_space_size, \n",
    "                                                  size=(len(env_info.agents))))[default_brain]\n",
    "        episode_rewards += env_info.rewards[0]\n",
    "        done = env_info.local_done[0]\n",
    "    print(\"Total reward this episode: {}\".format(episode_rewards))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Declare our model for the Q Network\n",
    "We'll use a a simple neural network with linear functions and then the result will be a RELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNetwork(nn.Module):\n",
    "    \"\"\"Actor (Policy) Model.\"\"\"\n",
    "\n",
    "    def __init__(self, state_size, action_size, neurons = 50, seed = None):\n",
    "        \"\"\"Initialize parameters and build model.\n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): Dimension of each state\n",
    "            action_size (int): Dimension of each action\n",
    "            seed (int): Random seed\n",
    "            \n",
    "        NOTE: skeleton provided by Udacity\n",
    "        \"\"\"\n",
    "        super(QNetwork, self).__init__()\n",
    "        if seed == 0 or seed:\n",
    "            self.seed = torch.manual_seed(seed)\n",
    "        else:\n",
    "            print('Seed is set to default None.')\n",
    "        self.l_in = nn.Linear(state_size,neurons)\n",
    "        self.hidden = nn.Linear(neurons, neurons)\n",
    "        self.l_out = nn.Linear(neurons, action_size)\n",
    "        self.activ = nn.ReLU()\n",
    "\n",
    "    def forward(self, state):\n",
    "        \"\"\"Build a network that maps state -> action values.\"\"\"\n",
    "        state = self.l_in(state)\n",
    "        state = self.activ(state)\n",
    "        state = self.hidden(state)\n",
    "        state = self.activ(state)\n",
    "        state = self.l_out(state)\n",
    "        return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Our agent\n",
    "Will be responsible of learning from the previous actions (with the ReplayBuffer) and deciding with action to take based on the current state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = int(1e5)  # replay buffer size\n",
    "BATCH_SIZE = 64         # minibatch size\n",
    "GAMMA = 0.99            # discount factor\n",
    "TAU = 1e-3              # for soft update of target parameters\n",
    "LR = 5e-4               # learning rate \n",
    "UPDATE_EVERY = 4        # how often to update the network\n",
    "\n",
    "#check if gpu/cuda is available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
    "WEIGHTS_FILE = \"Bananas-weights.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Agent:\n",
    "    def __init__(self, state_size, action_size, neurons = 50, seed=None):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.seed = random.seed(seed)\n",
    "        self.qnetwork_local = QNetwork(state_size, action_size, neurons, seed).to(device)\n",
    "        self.qnetwork_target = QNetwork(state_size, action_size, neurons, seed).to(device)\n",
    "        self.qnetwork_target.eval()\n",
    "        self.optimizer = optim.Adam(self.qnetwork_local.parameters(), lr=LR)\n",
    "        self.loss = torch.nn.MSELoss()\n",
    "        self.memory = ReplayBuffer(action_size, BUFFER_SIZE, BATCH_SIZE, seed)\n",
    "        self.t_step = 0\n",
    "    def update(self, state, action, reward, next_state, done):\n",
    "        # Save experience in replay memory\n",
    "        self.memory.add(state, action, reward, next_state, done)\n",
    "        \n",
    "        # Learn every UPDATE_EVERY time steps.\n",
    "        self.t_step = (self.t_step + 1) % UPDATE_EVERY\n",
    "        if self.t_step == 0:\n",
    "            # If enough samples are available in memory, get random subset and learn\n",
    "            if len(self.memory) > BATCH_SIZE:\n",
    "                experiences = self.memory.sample()\n",
    "                self.learn(experiences, GAMMA)\n",
    "    def act(self, state, eps=0.):\n",
    "        \"\"\"\n",
    "        Returns an action given the state.\n",
    "\n",
    "            state (array_like): current state\n",
    "            eps (float): epsilon, for epsilon-greedy action selection,\n",
    "                            if eps is too high, the chances the policy choses an option a random choice are higher, useful for exploration\n",
    "                            if eps is too low, will use the neural network to get the actions\n",
    "        \"\"\"\n",
    "        state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
    "        self.qnetwork_local.eval()\n",
    "        with torch.no_grad():\n",
    "            action_values = self.qnetwork_local(state)\n",
    "        self.qnetwork_local.train()\n",
    "\n",
    "        # Epsilon-greedy action selection\n",
    "        if random.random() > eps:\n",
    "            return np.argmax(action_values.cpu().data.numpy())\n",
    "        else:\n",
    "            return random.choice(np.arange(self.action_size))\n",
    "    def learn(self, experiences, gamma):\n",
    "        \"\"\"\n",
    "        Update value parameters using given batch of experience tuples.\n",
    "\n",
    "            experiences (Tuple[torch.Variable]): tuple of (s, a, r, s', done) tuples \n",
    "            gamma (float): discount factor\n",
    "        \"\"\"\n",
    "        states, actions, rewards, next_states, dones = experiences\n",
    "\n",
    "        ## TODO: compute and minimize the loss\n",
    "        \"*** YOUR CODE HERE ***\"\n",
    "        with torch.no_grad():\n",
    "            maxQ_target = self.qnetwork_target(next_states).detach().max(1)[0].unsqueeze(1)\n",
    "\n",
    "        targets = rewards + gamma*maxQ_target*(1-dones)\n",
    "        y = self.qnetwork_local(states)\n",
    "        y = y.gather(1,actions)\n",
    "        loss = self.loss(y,targets)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        # ------------------- update target network ------------------- #\n",
    "        self.soft_update(self.qnetwork_local, self.qnetwork_target, TAU)                     \n",
    "        \n",
    "    def soft_update(self, local_model, target_model, tau):\n",
    "        \"\"\"Soft update model parameters.\n",
    "        θ_target = τ*θ_local + (1 - τ)*θ_target\n",
    "        Params\n",
    "        ======\n",
    "            local_model (PyTorch model): weights will be copied from\n",
    "            target_model (PyTorch model): weights will be copied to\n",
    "            tau (float): interpolation parameter \n",
    "        \"\"\"\n",
    "        for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
    "            target_param.data.copy_(tau*local_param.data + (1.0-tau)*target_param.data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Declare our replay buffer\n",
    "Will be useful for the agent to take the N previous experiences to learn from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ReplayBuffer:\n",
    "    \"\"\"Fixed-size buffer to store experience tuples.\n",
    "    NOTE: provided by Udacity\"\"\"\n",
    "\n",
    "    def __init__(self, action_size, buffer_size, batch_size, seed):\n",
    "        \"\"\"Initialize a ReplayBuffer object.\n",
    "        Params\n",
    "        ======\n",
    "            action_size (int): dimension of each action\n",
    "            buffer_size (int): maximum size of buffer\n",
    "            batch_size (int): size of each training batch\n",
    "            seed (int): random seed\n",
    "        \"\"\"\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=buffer_size)  \n",
    "        self.batch_size = batch_size\n",
    "        self.experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "        self.seed = random.seed(seed)\n",
    "    \n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        \"\"\"Add a new experience to memory.\"\"\"\n",
    "        e = self.experience(state, action, reward, next_state, done)\n",
    "        self.memory.append(e)\n",
    "    \n",
    "    def sample(self):\n",
    "        \"\"\"Randomly sample a batch of experiences from memory.\"\"\"\n",
    "        experiences = random.sample(self.memory, k=self.batch_size)\n",
    "\n",
    "        states = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float().to(device)\n",
    "        actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).long().to(device)\n",
    "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float().to(device)\n",
    "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float().to(device)\n",
    "        dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(device)\n",
    "  \n",
    "        return (states, actions, rewards, next_states, dones)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the current size of internal memory.\"\"\"\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Do the training\n",
    "We will declare our training function with parameters so we can test how these affect to the performance of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dqn(env, agent, \n",
    "              solved_cond = 14.0, n_episodes=2000, max_t=1000,\n",
    "              eps_start=1.0, eps_end=0.01, eps_decay=0.995  ):\n",
    "    \"\"\"Train a Deep Q-Learning agent in the given environment.\n",
    "    Args\n",
    "    ====\n",
    "        env (object): Unity environment; the function uses the default brain\n",
    "        agent (object): RL agent \n",
    "    Params\n",
    "    ======\n",
    "        solved_cond (float): averaged score condition to consider the environment solved; average is over 100 episodes\n",
    "        n_episodes (int): maximum number of training episodes\n",
    "        max_t (int): maximum number of timesteps per episode\n",
    "        eps_start (float): starting value of epsilon, for epsilon-greedy action selection\n",
    "        eps_end (float): minimum value of epsilon\n",
    "        eps_decay (float): multiplicative factor (per episode) for decreasing epsilon\n",
    "    \"\"\"\n",
    "    \n",
    "    brain_name = env.brain_names[0]    # get the default brain\n",
    "    scores = []                        # list containing scores from each episode\n",
    "    scores_window = deque(maxlen=100)  # last 100 scores\n",
    "    eps = eps_start                    # initialize epsilon\n",
    "    \n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name] # reset the environment\n",
    "        state = env_info.vector_observations[0]\n",
    "        score = 0\n",
    "        for t in range(max_t):\n",
    "            action = int(agent.act(state, eps))\n",
    "            env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "            next_state = env_info.vector_observations[0]   # get the next state\n",
    "            reward = env_info.rewards[0]                   # get the reward\n",
    "            done = env_info.local_done[0]                  # check if the episode is done\n",
    "            agent.update(state, action, reward, next_state, done) # update agent Q-values and replay buffer\n",
    "            state = next_state\n",
    "            score += reward\n",
    "            if done:\n",
    "                break \n",
    "        scores_window.append(score)       # save most recent score\n",
    "        scores.append(score)              \n",
    "        eps = max(eps_end, eps_decay*eps) # decrease epsilon\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)), end=\"\")\n",
    "        if i_episode % 100 == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
    "        # Check if the averaged score is larger/equal than the condition for solving the environment\n",
    "        if np.mean(scores_window)>=solved_cond: \n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100, np.mean(scores_window)))\n",
    "            torch.save(agent.qnetwork_local.state_dict(), WEIGHTS_FILE)\n",
    "            break\n",
    "    return scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of actions: 4\n",
      "Number of states: 37\n"
     ]
    }
   ],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "# number of actions\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Number of actions:', action_size)\n",
    "state_size = len(env_info.vector_observations[0])\n",
    "print('Number of states:', state_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_MODEL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define agent\n",
    "agent = Agent(state_size=state_size, action_size=action_size, neurons=50, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD_MODEL:\n",
    "    agent.qnetwork_local.load_state_dict(torch.load(WEIGHTS_FILE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tAverage Score: 1.13\n",
      "Episode 200\tAverage Score: 3.56\n",
      "Episode 300\tAverage Score: 7.34\n",
      "Episode 400\tAverage Score: 10.74\n",
      "Episode 500\tAverage Score: 13.76\n",
      "Episode 514\tAverage Score: 14.02\n",
      "Environment solved in 414 episodes!\tAverage Score: 14.02\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# Train agent \n",
    "scores = train_dqn(env, agent)\n",
    "\n",
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 1.        , 0.        , 0.16101955,\n",
       "        1.        , 0.        , 0.        , 0.        , 0.04571758,\n",
       "        1.        , 0.        , 0.        , 0.        , 0.2937662 ,\n",
       "        0.        , 0.        , 1.        , 0.        , 0.14386636,\n",
       "        0.        , 0.        , 1.        , 0.        , 0.16776823,\n",
       "        1.        , 0.        , 0.        , 0.        , 0.04420976,\n",
       "        1.        , 0.        , 0.        , 0.        , 0.05423063,\n",
       "        0.        , 0.        ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name]\n",
    "env_info.vector_observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Testing agent's performance...\n",
      "Done!\n",
      "Score: 16.0\n"
     ]
    }
   ],
   "source": [
    "#Show agent sampling correct bananas\n",
    "print(\"\\n Testing agent's performance...\")\n",
    "env_info = env.reset(train_mode=False)[brain_name] # reset the environment\n",
    "state = env_info.vector_observations[0]            # get the current state\n",
    "score = 0                                          # initialize the score\n",
    "eps = 0.01\n",
    "while True:\n",
    "    action = int(agent.act(state, eps))  # select an action\n",
    "    env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "    next_state = env_info.vector_observations[0]   # get the next state\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    score += reward                                # update the score\n",
    "    state = next_state                             # roll over the state to next time step\n",
    "    #time.sleep(0.1)\n",
    "    if done:                                       # exit loop if episode finished\n",
    "        print('Done!')\n",
    "        print(\"Score: {}\".format(score))\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close the environment when finished\n",
    "When we are finished using an environment, we can close it with the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnityEnvironmentException",
     "evalue": "No Unity environment is loaded.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnityEnvironmentException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-1baceacf4cb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/disco-grande/udacity/drl-aud/python/unityagents/environment.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mUnityEnvironmentException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No Unity environment is loaded.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_close\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnityEnvironmentException\u001b[0m: No Unity environment is loaded."
     ]
    }
   ],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
